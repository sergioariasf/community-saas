# Flujo de Trabajo y Herramientas üõ†Ô∏è

## 1. Fase de Ingesta üì•

Esta fase es la primera l√≠nea de procesamiento y la m√°s cr√≠tica para la calidad de los datos.

- **PDF editable (.pdf):** Si el documento es un PDF digital con texto seleccionable, puedes usar una librer√≠a como **`PyPDFLoader` de LangChain**. Esta herramienta es eficiente y r√°pida para extraer el texto puro sin necesidad de OCR.
- **PDF no editable (imagen):** Si el PDF es un documento escaneado (una imagen), necesitar√°s **OCR**. La **Google Vision API** es la herramienta ideal aqu√≠. Su motor de OCR es muy preciso y est√° optimizado para procesar documentos, tablas y otros formatos complejos.
- **OCR de muy mala calidad:** Si el resultado de Google Vision sigue siendo deficiente (ej. por baja resoluci√≥n o texto borroso), aqu√≠ interviene un **LLM (Gemini 1.5 Flash)** para una correcci√≥n y limpieza sem√°ntica. Puedes pasar el texto de OCR "sucio" a Gemini con un _prompt_ que lo instruya a "corregir errores de transcripci√≥n" y "normalizar el texto".

## 2. Fase de Identificaci√≥n (LLM) üïµÔ∏è‚Äç‚ôÇÔ∏è

Una vez que el texto est√° en un formato legible, entra en juego la inteligencia del modelo.

- **Identificaci√≥n y Extracci√≥n de Datos:** El **LLM (Gemini 1.5 Flash)** es la herramienta central en esta fase. Se utiliza un _prompt_ para clasificar el tipo de documento (factura, acta, etc.) y extraer los metadatos clave relevantes. Esta tarea es perfecta para la capacidad de razonamiento de Gemini.

## 3. Fase de Procesamiento General (LLM) üß†

Este paso es opcional pero muy valioso, y tu enfoque de "leer el documento completo" es muy inteligente.

- **Extracci√≥n de Contexto:** El **LLM (Gemini 1.5 Flash)** lee el texto completo del documento (ya limpio) y genera un resumen conciso o una lista de metadatos m√°s detallada. Esto proporciona un contexto de alto nivel que se puede adjuntar a cada _chunk_ individual, mejorando la b√∫squeda posterior.

## 4. Fase de Procesamiento de Divisi√≥n (LangChain) ‚úÇÔ∏è

Una vez que el texto est√° listo y con el contexto de metadatos, se divide.

- **Chunking y Enriquecimiento:** **LangChain** es la herramienta clave aqu√≠. Su `RecursiveCharacterTextSplitter` se encarga de dividir el texto de manera inteligente, conservando la estructura sem√°ntica. M√°s importante a√∫n, LangChain te permite adjuntar los metadatos generados por Gemini en la fase anterior a cada _chunk_ antes de que sean almacenados.

## 5. Fase de Almacenamiento üíæ

Finalmente, los datos procesados se guardan de forma eficiente para la recuperaci√≥n.

- **Vectorizaci√≥n y Persistencia:** El modelo de **Embedding de Google** (o cualquier otro compatible con LangChain) convierte los _chunks_ en vectores. El conector de **LangChain** para **Supabase (PostgreSQL con `pgvector`)** se encarga de la inserci√≥n. Este paso almacena el texto, los metadatos y el vector en tu base de datos para futuras consultas.

---

# Visi√≥n General del Pipeline üó∫Ô∏è

Este flujo de trabajo crea un sistema RAG muy sofisticado. Cada fase se apoya en una herramienta especializada para su tarea, mientras que **LangChain** act√∫a como el pegamento que orquesta todo el proceso, y **Supabase** como la base de datos que lo respalda.
