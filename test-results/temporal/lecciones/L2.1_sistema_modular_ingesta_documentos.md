# L2.1 - Sistema Modular de Ingesta de Documentos RAG

## Contexto del Proyecto

**Proyecto**: Community SaaS (Next.js 15 + Supabase)  
**Estado actual**: Sistema bÃ¡sico de upload y extracciÃ³n funcionando  
**Objetivo**: Evolucionar a sistema RAG completo con arquitectura modular  
**Base de datos**: Supabase PostgreSQL con pgvector para embeddings  
**Experiencia previa**: Proyecto RAG completo validado en `/proyectos/RAG/`

## AnÃ¡lisis de Viabilidad TÃ©cnica

### âœ… PLAN APROBADO - Altamente Viable

El plan propuesto es tÃ©cnicamente sÃ³lido y factible por:

1. **Base tecnolÃ³gica establecida**: Sistema de extracciÃ³n PDF ya funcionando
2. **Experiencia validada**: Proyecto RAG demuestra dominio completo del pipeline
3. **Arquitectura modular**: DiseÃ±o sigue patrones probados y escalables
4. **IntegraciÃ³n natural**: Se alinea con Next.js + Supabase existente
5. **Flexibilidad real**: Procesos configurables segÃºn necesidad

## Arquitectura del Sistema Modular

### Estructura de Archivos Detallada

```
src/lib/ingesta/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ types.ts              # Types e interfaces compartidos
â”‚   â”œâ”€â”€ constants.ts          # Constantes del sistema
â”‚   â”œâ”€â”€ errors.ts            # Error handling personalizado
â”‚   â””â”€â”€ pipeline.ts          # Orchestrator principal
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ extraction/           # âœ… EXTRACCIÃ“N DE TEXTO
â”‚   â”‚   â”œâ”€â”€ index.ts         # Exports principales
â”‚   â”‚   â”œâ”€â”€ types.ts         # Types especÃ­ficos
â”‚   â”‚   â”œâ”€â”€ pdfTextExtraction.ts    # PDF editable âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ ocrExtraction.ts        # OCR wrapper (Google Vision) âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ llmExtraction.ts        # LLM directo (Gemini) [FUTURO]
â”‚   â”‚   â””â”€â”€ extractionOrchestrator.ts  # Strategy pattern [FUTURO]
â”‚   â”œâ”€â”€ classification/       # âœ… CLASIFICACIÃ“N DE DOCUMENTOS
â”‚   â”‚   â”œâ”€â”€ index.ts         # Exports principales âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ types.ts         # Types especÃ­ficos âœ… IMPLEMENTADO
â”‚   â”‚   â””â”€â”€ documentClassifier.ts   # IA classification âœ… IMPLEMENTADO
â”‚   â”œâ”€â”€ metadata/            # ğŸ†• EXTRACCIÃ“N DE METADATOS
â”‚   â”‚   â”œâ”€â”€ contracts/       # ğŸ“‹ Contratos de metadatos por tipo
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts     # Tipos base comunes âœ… IMPLEMENTADO
â”‚   â”‚   â”‚   â”œâ”€â”€ actaContract.ts        # Contrato ACTA âœ… IMPLEMENTADO
â”‚   â”‚   â”‚   â”œâ”€â”€ contratoContract.ts    # Contrato CONTRATO [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ facturaContract.ts     # Contrato FACTURA [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ comunicadoContract.ts  # Contrato COMUNICADO [FUTURO]
â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # Exporta todos los contratos âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ extractors/      # ğŸ¤– Extractores de metadatos OVERVIEW (nivel documento)
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts     # Tipos para extractors
â”‚   â”‚   â”‚   â”œâ”€â”€ actaMetadataExtractor.ts      # Metadatos globales ACTA (Gemini)
â”‚   â”‚   â”‚   â”œâ”€â”€ contratoMetadataExtractor.ts  # Metadatos globales CONTRATO [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ facturaMetadataExtractor.ts   # Metadatos globales FACTURA [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ comunicadoMetadataExtractor.ts # Metadatos bÃ¡sicos COMUNICADO [FUTURO]
â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # Exporta todos los extractors
â”‚   â”‚   â”œâ”€â”€ chunkers/        # âœ‚ï¸ Generadores de chunks con metadatos especÃ­ficos
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts     # Tipos para chunkers
â”‚   â”‚   â”‚   â”œâ”€â”€ actaChunker.ts         # Divide ACTA en chunks + metadatos chunk-especÃ­ficos
â”‚   â”‚   â”‚   â”œâ”€â”€ contratoChunker.ts     # Divide CONTRATO en chunks [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ facturaChunker.ts      # Divide FACTURA en chunks [FUTURO]
â”‚   â”‚   â”‚   â”œâ”€â”€ comunicadoChunker.ts   # Divide COMUNICADO en chunks [FUTURO]
â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # Exporta todos los chunkers
â”‚   â”‚   â”œâ”€â”€ metadataOrchestrator.ts  # ğŸ¯ Orquestador principal (overview + chunking)
â”‚   â”‚   â””â”€â”€ index.ts         # API pÃºblica del mÃ³dulo
â”‚   â”œâ”€â”€ processing/          # ğŸ”„ PROCESAMIENTO Y CHUNKING
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â”œâ”€â”€ chunker.ts             # Text chunking (adaptado del RAG)
â”‚   â”‚   â”œâ”€â”€ embedder.ts            # Embeddings (adaptado del RAG)
â”‚   â”‚   â””â”€â”€ processingOrchestrator.ts
â”‚   â””â”€â”€ storage/             # ğŸ’¾ ALMACENAMIENTO VECTORIAL
â”‚       â”œâ”€â”€ index.ts
â”‚       â”œâ”€â”€ types.ts
â”‚       â”œâ”€â”€ vectorStore.ts         # Supabase + pgvector
â”‚       â”œâ”€â”€ metadataStore.ts       # Metadata storage
â”‚       â””â”€â”€ storageOrchestrator.ts
â”œâ”€â”€ processes/               # ğŸš€ PROCESOS CONFIGURABLES
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ types.ts
â”‚   â”œâ”€â”€ basicUpload.ts        # Proceso 1: Solo upload
â”‚   â”œâ”€â”€ uploadExtract.ts      # Proceso 2: Upload + extracciÃ³n
â”‚   â”œâ”€â”€ uploadClassify.ts     # Proceso 3: Upload + extracciÃ³n + clasificaciÃ³n
â”‚   â”œâ”€â”€ uploadMetadata.ts     # Proceso 4: Upload + extracciÃ³n + clasificaciÃ³n + metadata
â”‚   â””â”€â”€ fullRAGPipeline.ts    # Proceso 5: Pipeline completo RAG
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ moduleConfig.ts       # Configuraciones por mÃ³dulo
â”‚   â”œâ”€â”€ processConfig.ts      # Configuraciones por proceso
â”‚   â””â”€â”€ environmentConfig.ts # Variables de entorno
â””â”€â”€ utils/
    â”œâ”€â”€ index.ts
    â”œâ”€â”€ validation.ts         # Validaciones
    â”œâ”€â”€ monitoring.ts         # MÃ©tricas y logging
    â””â”€â”€ migration.ts          # Helpers para migrar del RAG
```

## **Arquitectura de Metadatos: Dos Niveles**

### **ğŸ“„ NIVEL 1: Document Overview (Implementado)**
**Responsabilidad**: Metadatos globales de TODO el documento
```typescript
// UN solo conjunto de metadatos para el documento completo:
ActaMetadataStructure {
  chunk_type: "document_overview",
  lugar: "Las Rozas",
  tipo_reunion: "extraordinaria", 
  presidente_entrante: "StefanÃ­a Nitto",
  topic_keywords: ["Piscina", "Balance", "Administracion"],
  decisiones_principales: ["Renovar piscina", "Aprobar presupuesto"]
}
```

**MÃ³dulos**:
- `actaContract.ts`: Define estructura y validaciones âœ…
- `actaMetadataExtractor.ts`: Extrae metadatos globales con Gemini
- **Ventajas**: Simple, rÃ¡pido, econÃ³mico (~1000 tokens)
- **Uso**: BÃºsquedas, filtros, clasificaciÃ³n general

### **ğŸ“‹ NIVEL 2: Per-Chunk (Futuro)**
**Responsabilidad**: Metadatos especÃ­ficos para CADA chunk/pÃ¡rrafo
```typescript
// MÃºltiples chunks, cada uno con sus metadatos especÃ­ficos:
[
  ActaMetadataStructure { chunk_type: "content_chunk", topic_keywords: ["Piscina"], category: "tecnico" },
  ActaMetadataStructure { chunk_type: "content_chunk", topic_keywords: ["Balance"], category: "financiero" },  
  ActaMetadataStructure { chunk_type: "content_chunk", topic_keywords: ["Administracion"], category: "administrativo" }
]
```

**MÃ³dulos**:
- `actaChunker.ts`: Divide documento + extrae metadatos por chunk
- **Ventajas**: BÃºsqueda granular, mejor relevancia RAG
- **Desventajas**: MÃ¡s complejo, mÃ¡s costoso (~5000 tokens)
- **Uso**: RAG search, respuestas contextuales especÃ­ficas

### **ğŸš€ Flujo de Procesamiento Completo**
```
PDF â†’ pdfTextExtraction â†’ documentClassifier â†’ actaMetadataExtractor â†’ [actaChunker] â†’ Storage
      â†“                   â†“                    â†“                        â†“
   "texto..."         "acta"             metadatos overview      chunks individuales
                                         (SIEMPRE)               (OPCIONAL)
```

### **âš™ï¸ ConfiguraciÃ³n Modular**
```typescript
ProcessConfig {
  extraction: true,        // Siempre extraer texto
  classification: true,    // Siempre clasificar tipo
  metadata_overview: true, // Siempre metadatos globales
  chunking: false         // Activar solo si necesitas RAG granular
}
```

### PROCESOS

1. Extracion de metadatos

- pdfTextExtraction ( si falla) ocrExtraction
  - documentClassifier (depende de pdfTextExtraction)
-

2. Extracion de metadatos y creacion de chunks

## Patrones de DiseÃ±o Implementados

### 1. Strategy Pattern

Para algoritmos intercambiables:

```typescript
interface ExtractionStrategy {
  extract(buffer: Buffer): Promise<ExtractionResult>;
}

class PDFParseStrategy implements ExtractionStrategy {}
class OCRStrategy implements ExtractionStrategy {}
class LLMStrategy implements ExtractionStrategy {}
```

### 2. Pipeline Pattern

Para orchestrar flujo de procesamiento:

```typescript
class DocumentPipeline {
  constructor(private modules: ModuleConfig[]) {}

  async execute(input: ProcessInput): Promise<ProcessResult> {
    let result = input;
    for (const module of this.modules) {
      result = await this.executeModule(module, result);
    }
    return result;
  }
}
```

### 3. Factory Pattern

Para crear instancias de mÃ³dulos:

```typescript
class ModuleFactory {
  static create(type: ModuleType, config: ModuleConfig): ProcessingModule {
    switch (type) {
      case 'extraction':
        return new ExtractionModule(config);
      case 'classification':
        return new ClassificationModule(config);
      // ...
    }
  }
}
```

## Tipos y Contratos

### Core Types

```typescript
export interface ModuleConfig {
  name: string;
  version: string;
  enabled: boolean;
  parameters: Record<string, any>;
}

export interface ProcessResult {
  success: boolean;
  documentId?: string;
  error?: string;
  processingStatus: 'processing' | 'completed' | 'error';
  steps: ProcessSteps;
  metrics: ProcessMetrics;
}

export interface ProcessSteps {
  upload: boolean;
  extraction: boolean;
  classification: boolean;
  chunking: boolean;
  embedding: boolean;
  storage: boolean;
}
```

### Module Interfaces

```typescript
export interface ProcessingModule {
  configure(config: ModuleConfig): Promise<void>;
  process(input: any): Promise<any>;
  validate(input: any): Promise<boolean>;
  getMetrics(): ModuleMetrics;
}
```

## IntegraciÃ³n con Supabase y pgvector

### Extensiones de Base de Datos

```sql
-- Habilitar pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- Extender tabla documents existente
ALTER TABLE documents ADD COLUMN IF NOT EXISTS vector_status VARCHAR(20) DEFAULT 'pending';
ALTER TABLE documents ADD COLUMN IF NOT EXISTS chunk_count INTEGER DEFAULT 0;
ALTER TABLE documents ADD COLUMN IF NOT EXISTS embedding_model VARCHAR(100);

-- Nueva tabla para embeddings
CREATE TABLE document_embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    chunk_content TEXT NOT NULL,
    chunk_metadata JSONB,
    embedding vector(768), -- Ajustar dimensiÃ³n segÃºn modelo
    similarity_threshold FLOAT DEFAULT 0.8,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Ãndices para bÃºsqueda vectorial eficiente
CREATE INDEX ON document_embeddings USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Ãndice para filtros por documento
CREATE INDEX ON document_embeddings (document_id, chunk_index);

-- Nueva tabla para metadatos semÃ¡nticos
CREATE TABLE document_semantic_metadata (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
    topics JSONB,
    entities JSONB,
    keywords JSONB,
    summary TEXT,
    confidence_score FLOAT,
    extracted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### Storage Module Implementation

```typescript
export class VectorStore {
  constructor(private supabase: SupabaseClient) {}

  async storeEmbeddings(
    documentId: string,
    chunks: ChunkData[],
    embeddings: number[][]
  ): Promise<void> {
    const embeddingData = chunks.map((chunk, index) => ({
      document_id: documentId,
      chunk_index: index,
      chunk_content: chunk.content,
      chunk_metadata: chunk.metadata,
      embedding: embeddings[index],
    }));

    await this.supabase.from('document_embeddings').insert(embeddingData);
  }

  async searchSimilar(
    query: number[],
    limit: number = 10,
    threshold: number = 0.8
  ): Promise<SearchResult[]> {
    const { data, error } = await this.supabase.rpc('match_documents', {
      query_embedding: query,
      match_threshold: threshold,
      match_count: limit,
    });

    return data || [];
  }
}
```

## Procesos Configurables

### Proceso 1: Solo Upload

```typescript
export async function basicUploadProcess(
  formData: FormData
): Promise<ProcessResult> {
  const pipeline = new DocumentPipeline([
    ModuleFactory.create('upload', uploadConfig),
  ]);

  return pipeline.execute(formData);
}
```

### Proceso 4: Pipeline Completo RAG

```typescript
export async function fullRAGPipelineProcess(
  formData: FormData
): Promise<ProcessResult> {
  const pipeline = new DocumentPipeline([
    ModuleFactory.create('upload', uploadConfig),
    ModuleFactory.create('extraction', extractionConfig),
    ModuleFactory.create('classification', classificationConfig),
    ModuleFactory.create('processing', processingConfig),
    ModuleFactory.create('storage', storageConfig),
  ]);

  return pipeline.execute(formData);
}
```

## MigraciÃ³n del Proyecto RAG Existente

### Fase 1: Adaptar MÃ³dulos Core (Semana 1-2)

**Chunking Module Migration:**

```bash
# Del RAG: /core/chunking/chunking_module.py
# Al SaaS: /src/lib/ingesta/modules/processing/chunker.ts

# Estrategias a migrar:
- FixedSizeStrategy -> fixedSizeChunking.ts
- SemanticStrategy -> semanticChunking.ts
- LLMStrategy -> llmChunking.ts
```

**Embedding Module Migration:**

```bash
# Del RAG: /core/embedding/embedding_module.py
# Al SaaS: /src/lib/ingesta/modules/processing/embedder.ts

# Proveedores a migrar:
- GoogleEmbeddings -> googleEmbeddingsProvider.ts
- OpenAIEmbeddings -> openaiEmbeddingsProvider.ts
```

**Storage Module Migration:**

```bash
# Del RAG: /core/storage/storage_module.py
# Al SaaS: /src/lib/ingesta/modules/storage/vectorStore.ts

# Migrar de ChromaDB a Supabase + pgvector
```

### Fase 2: IntegraciÃ³n con Next.js (Semana 3-4)

**Server Actions Integration:**

```typescript
'use server';

import { DocumentPipeline } from '@/lib/ingesta/core/pipeline';
import { ProcessType } from '@/lib/ingesta/core/types';

export async function processDocumentWithRAG(
  formData: FormData,
  processType: ProcessType = 'full'
): Promise<ProcessResult> {
  try {
    const pipeline = await DocumentPipeline.create(processType);
    return await pipeline.execute(formData);
  } catch (error) {
    return {
      success: false,
      error: error.message,
      processingStatus: 'error',
      steps: createEmptySteps(),
    };
  }
}
```

### Fase 3: UI y ConfiguraciÃ³n (Semana 5)

**Process Selection UI:**

```tsx
export function ProcessSelectionForm() {
  const [processType, setProcessType] = useState<ProcessType>('basic');

  return (
    <div className="space-y-4">
      <RadioGroup value={processType} onValueChange={setProcessType}>
        <div className="flex items-center space-x-2">
          <RadioGroupItem value="basic" id="basic" />
          <Label htmlFor="basic">Solo Upload</Label>
        </div>
        <div className="flex items-center space-x-2">
          <RadioGroupItem value="extract" id="extract" />
          <Label htmlFor="extract">Upload + ExtracciÃ³n</Label>
        </div>
        <div className="flex items-center space-x-2">
          <RadioGroupItem value="classify" id="classify" />
          <Label htmlFor="classify">Upload + ClasificaciÃ³n</Label>
        </div>
        <div className="flex items-center space-x-2">
          <RadioGroupItem value="full" id="full" />
          <Label htmlFor="full">Pipeline RAG Completo</Label>
        </div>
      </RadioGroup>

      <ProcessConfigEditor processType={processType} />
    </div>
  );
}
```

## Performance y Escalabilidad

### Optimizaciones Implementadas

1. **Procesamiento AsÃ­ncrono**

   - Background jobs para chunking pesado
   - Queue system para embeddings
   - Progress tracking en tiempo real

2. **Cache Inteligente**

   - Cache de embeddings por hash de contenido
   - Cache de clasificaciones por tipo de documento
   - Cache de metadatos extraÃ­dos

3. **Batch Processing**
   - AgrupaciÃ³n de operaciones vectoriales
   - InserciÃ³n en lotes para mejor performance
   - ParalelizaciÃ³n de embeddings

### Monitoring y MÃ©tricas

```typescript
export interface ProcessMetrics {
  totalTime: number;
  moduleTimings: Record<string, number>;
  chunksGenerated: number;
  embeddingsCreated: number;
  storageOperations: number;
  cacheHits: number;
  errors: string[];
}

export class MetricsCollector {
  static collect(pipeline: DocumentPipeline): ProcessMetrics {
    return {
      totalTime: pipeline.getTotalExecutionTime(),
      moduleTimings: pipeline.getModuleTimings(),
      chunksGenerated: pipeline.getChunksCount(),
      embeddingsCreated: pipeline.getEmbeddingsCount(),
      storageOperations: pipeline.getStorageOpsCount(),
      cacheHits: pipeline.getCacheHits(),
      errors: pipeline.getErrors(),
    };
  }
}
```

## GestiÃ³n de Errores y Fallbacks

### Error Handling Strategy

```typescript
export class ProcessingError extends Error {
  constructor(
    public module: string,
    public stage: string,
    public originalError: Error,
    public recoverable: boolean = false
  ) {
    super(`${module}:${stage} - ${originalError.message}`);
  }
}

export class ErrorHandler {
  static async handleModuleError(
    error: ProcessingError,
    context: ProcessingContext
  ): Promise<ProcessingResult> {
    if (error.recoverable) {
      return await this.attemptRecovery(error, context);
    }

    return this.createErrorResult(error);
  }

  private static async attemptRecovery(
    error: ProcessingError,
    context: ProcessingContext
  ): Promise<ProcessingResult> {
    // Implementar estrategias de fallback especÃ­ficas por mÃ³dulo
    switch (error.module) {
      case 'extraction':
        return await this.fallbackExtraction(context);
      case 'classification':
        return await this.fallbackClassification(context);
      default:
        return this.createErrorResult(error);
    }
  }
}
```

## Testing Strategy

### MÃ³dulos de Test

```typescript
// test/modules/extraction.test.ts
describe('Extraction Module', () => {
  test('should extract text from PDF', async () => {
    const module = new ExtractionModule(testConfig);
    const result = await module.process(testPDFBuffer);

    expect(result.success).toBe(true);
    expect(result.text.length).toBeGreaterThan(0);
  });
});

// test/processes/fullPipeline.test.ts
describe('Full RAG Pipeline', () => {
  test('should process document end-to-end', async () => {
    const pipeline = await DocumentPipeline.create('full');
    const result = await pipeline.execute(testFormData);

    expect(result.success).toBe(true);
    expect(result.steps.embedding).toBe(true);
    expect(result.steps.storage).toBe(true);
  });
});
```

## Plan de ImplementaciÃ³n

### Sprint 1: Core Infrastructure (2 semanas)

- [x] AnÃ¡lisis y documentaciÃ³n (este documento)
- [ ] Setup estructura de carpetas
- [ ] Implementar core types y interfaces
- [ ] Migrar extraction module bÃ¡sico
- [ ] Tests unitarios bÃ¡sicos

### Sprint 2: Module Migration (2 semanas)

- [ ] Migrar chunking module del RAG
- [ ] Migrar embedding module del RAG
- [ ] Adaptar storage para Supabase + pgvector
- [ ] Implementar pipeline orchestrator
- [ ] Tests de integraciÃ³n

### Sprint 3: Process Implementation (2 semanas)

- [ ] Implementar 4 procesos configurables
- [ ] IntegraciÃ³n con Server Actions existentes
- [ ] UI para selecciÃ³n de procesos
- [ ] Sistema de configuraciÃ³n
- [ ] Tests end-to-end

### Sprint 4: Production Ready (1 semana)

- [ ] Error handling robusto
- [ ] Monitoring y mÃ©tricas
- [ ] Performance optimizations
- [ ] Documentation completa
- [ ] Deploy y validaciÃ³n

## Conclusiones

### Beneficios del Sistema Modular

1. **Flexibilidad**: Procesos adaptables segÃºn necesidad
2. **Mantenibilidad**: MÃ³dulos independientes y testeables
3. **Escalabilidad**: Arquitectura preparada para crecimiento
4. **ReutilizaciÃ³n**: Aprovechamiento del cÃ³digo RAG validado
5. **Performance**: Optimizaciones especÃ­ficas por mÃ³dulo

### PrÃ³ximos Pasos

1. **Validar con el equipo** este plan arquitectÃ³nico
2. **Definir prioridades** de implementaciÃ³n segÃºn necesidad
3. **Setup del entorno** de desarrollo con las nuevas estructuras
4. **Comenzar migraciÃ³n** con mÃ³dulos mÃ¡s crÃ­ticos
5. **Implementar testing** desde el inicio para garantizar calidad

### Riesgos Identificados

1. **Complejidad de migraciÃ³n**: Mitigado con enfoque incremental
2. **Performance de pgvector**: Mitigado con Ã­ndices adecuados
3. **IntegraciÃ³n con cÃ³digo existente**: Mitigado con interfaces estÃ¡ndar

Este sistema modular representa una evoluciÃ³n natural del proyecto, aprovechando la experiencia del RAG existente mientras se integra perfectamente con la arquitectura Next.js + Supabase actual.

---

**Documento generado**: 2025-09-13  
**VersiÃ³n**: 1.0  
**Estado**: Propuesta aprobada para implementaciÃ³n
